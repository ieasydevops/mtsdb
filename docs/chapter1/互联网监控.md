# 互联网监控场景下，时间序列数据的特性

## 时序数据特性的划分

互联网企业中，服务监控是运维体系中很重要的一个环节。
通常监控可按照数据的类型，分成如下三大类

- Metrics，指标类。用来刻画 某一个监控对象某个属性特征值，随时间的变化。通常，用Metric来定义指标的名称，基于多维度的标签来定义该指标的归属，Value 值来表征属性在某个时刻的状态值。 


- Log， 通常来自服务的应用日志，基础设施的系统日志，中间件的日志等。日志的内容和格式可能各式各样。比如，文本类型，JSON类型，等等。这些数据通常通过数据的清洗或格式化处理，可以转化为 键，值 对- 即[（K，V）] 的序列。


- Tracing，服务间调用链的关系。比如： 用来记录在分布式服务中，一个远程调用的调用者，被调者的关系，以及调用的耗时情况。可以根据一个请求入口，带上trace Id, 并将trace id 透传到请求链中，并基于此来构建服务的动态调用拓扑关系。


## 时间序列数据的特性

### 写特性：持续的大规模并发写入，插入操作频繁，但无更新操作

* 为什么是持续大规模的并发写入呢？

	    举个例子：举个例子假设现在监控系统有1万台服务器，每个服务器需要采集200个指标，再加上这个
	    机器上部署的服务，假设一个服务对应200个指标，一个周期内我们需要采集的指标就会有400个，通
	    常我们采集周期的频率设为10秒，那么每10秒就会产生400万个指标，每秒的写入量就需要至少40万
	    的TPS，这些还不包括，网络层面的监控数据，以及应用RPC调用层，用户访问层等的数据。

* 为什么 插入操作频繁，但无更新操作。

	    这个通俗的理解就是，历史发生的事情，基本不可逆。这也是时间序列数据库优化的一个突破口。


### 读特性 

- 热点数据并发读，冷数据读的场景频率很低

	    热点数据可分为：最近几个周期内的，最近几个小时的，以及最近2周的，以及其它的。
	    最近几个周期的数据，参与用户的告警策略计算，和统计类的预计算。
	    最近2小时的，这部分数据，通常用户实时盯屏的OP人员，或用于监控巡检
	    最近2周的数据，通常监控大盘，数据同环比等场景。
	    在久的数据，一般用于事后分析，定位问题，或做AI计算用的。读取频率会很低。

- 一次读取多个序列在某段时间的数据，或一个序列多个周期的数据。

   第一种场景侧重于多维度联合分析

   第二种侧重与从历史的趋势中分析




## 数据模型

- Metrics. 

  比较具有典型代表的是Prometheus的数据结构：

  metric{k1=v1,k2=v2,...} 

  泛化标示：
  { __name__ ="metricName",...} Vaule  timestamp

  可以简化表达为：

  {t,[{(k,v)},V]}, 其中，V 为指标类型的数据


 
- Log 通常服务的应用日志。基本可转化为[（K，V）] 的 键，值对的序列。
  
  {t,[(k,v)]}
  

- Tracing

  Node {
    Id   String,
    Data Object,
    Child List <Node>
  }
  
  

## 一些值得思考的问题

### Metrics 和 Tracing 以及Log 的数据模型是否可以统一

