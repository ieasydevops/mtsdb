# 1.2 时间序列数据的特性

## 1.2.1 业务背景

本章，我们将目光聚焦在互联网企业中，服务监控的这个领域。

我们知道，根据服务监控数据的类型，通常监控可按照数据的类型，分成如下三大类

- Metrics，指标类。用来刻画 某一个监控对象某个属性特征值，随时间的变化。通常，用Metric来定义指标的名称，基于多维度的标签来定义该指标的归属，Value 值来表征属性在某个时刻的状态值。 


- Log， 通常来自服务的应用日志，基础设施的系统日志，中间件的日志等。日志的内容和格式可能各式各样。比如，文本类型，JSON类型，等等。这些数据通常通过数据的清洗或格式化处理，可以转化为 键，值 对- 即[（K，V）] 的序列。


- Tracing，服务间调用链的关系。比如： 用来记录在分布式服务中，一个远程调用的调用者，被调者的关系，以及调用的耗时情况。可以根据一个请求入口，带上trace Id, 并将trace id 透传到请求链中，并基于此来构建服务的动态调用拓扑关系。




## 1.2.2 Log,Metrics,Tracing 数据模型之间的转化或关联

### 1.2.2.1 Log-> Metrics

在实践过程中，Log类型的数据通常有两种场景，

其一： 关键字的统计，报警。 我们对不同来源的日志做格式解析，数据清洗，目的是希望能产生报表，
以可视化的形式，对业务系统作出评估和判断。实践中，可通过logstash, Flink, Spark，
grok等方式做数据格式转化。最终输出为Metric形式的数据。

其二： 问题详情排查。这种场景下，对原始日志不做过多的处理，转化为（K，V），JSON形式的数据
后，丢到ELK集群中，做日后查询。通常是，通过Metric 定位大概的日志信息，在根据索引查看详情
来定位。

### 1.2.2.2 Tracing -> Metrics

Tracing 比较特殊的点，在于能记录下一个请求事物中，上下游的关联关系，这对于构建服务的动态拓扑
关系非常有帮助。但大部分场景下，我们还是会将请求中所涉及的关键指标以Metric的形式暴露出来，输出为统计的报表。
对业务Tracing的数据模型做进一步分析可知，Tracing的 的数据模型中，除了TraceAction类的数据模型，
涉及 父子数关系，其它的统计数据模型，都可以转化为Metric的数据。


### 1.2.2.3 Metric - > Log , Tracing

在问题的发现，或故障定位过程中，一般都是基于Metric类型的指标，配置相应的告警策略，
在告警事件驱动下，带着Metric中包含的标签，来进一步定位到Log ,Tracing。

通常，首先通过Metric 定位到服务接口级；然后，基于标签和时间维度的范围,结合
Log，和Tracing 定位到具体的实例。



## 1.2.3 时间序列数据的特性分析

上文，我们分析在互联网监控业务场景下，多种模型的数据最终会转化为Metric 类型的数据，因此我们将
进一步分析以Metic类型的数据的特性，以期对时间序列数据库的设计实现提供一些原则性的指导。




### 1.2.3.1 写特性： 持续的大规模并发写入，插入操作频繁，但无更新操作

#### 序列基数很大，千万到亿，甚至兆的量级，而且是持续写
    
    举个例子：举个例子假设现在监控系统有1万台服务器，每个服务器需要采集200个指标，再加上这个
	  机器上部署的服务，假设一个服务对应200个指标，一个周期内我们需要采集的指标就会有400个，通
	  常我们采集周期的频率设为10秒，那么每10秒就会产生400万个指标，每秒就需要至少40万的TPS，
    这些还不包括，网络层面的监控数据，以及应用RPC调用层，用户访问层等的数据。

#### 大部分的负载压力是追加插入和写

	  这个通俗的理解就是，历史发生的事情，基本不可逆。这也是时间序列数据库优化的一个突破口。


#### 大规模的数据删除（数据过期）

     数据过期时的删除，本质也是写操作，这个量级和写入的量级相同


### 1.2.3.2 读特性：热点数据并发读，冷数据读的场景频率很低

*  热点数据并发读，冷数据读的场景频率很低

	  热点数据可分为：最近几个周期内的，最近几个小时的，以及最近2周的，以及其它的。

	  最近几个周期的数据，参与用户的告警策略计算，和统计类的预计算。这部分也是造成
    高并发读的根本原因。很多人认为，在普通场景下，用户不会一次查询成千上万的序列来看图，
    但实际上，我们需要实时的聚合出这些数据，一方面做告警，另一方面做为预计算的结果，供
    后续的查询和报表。

	  最近2小时的，这部分数据，通常对应实时盯屏的OP人员，或用于监控巡检.

	  最近2周的数据，通常监控大盘，数据同环比等场景。

	  更久一些的数据，一般用于事后分析，定位问题，或做AI计算用的。读取频率会很低。

* 一次读取多个序列在某段时间的数据，或一个序列多个周期的数据。

   第一种场景侧重于多维度联合分析

   第二种侧重与从历史的趋势中分析




## 1.2.4 数据模型

- Metrics. 

  比较具有典型代表的是Prometheus的数据结构：

  metric{k1=v1,k2=v2,...} 

  泛化标示：
  { __name__ ="metricName",...} Vaule  timestamp

  可以简化表达为：

  {t,[{(k,v)},V]}, 其中，V 为指标类型的数据


 
- Log 通常服务的应用日志。基本可转化为[（K，V）] 的 键，值对的序列。
  
  {t,[(k,v)]}
  

- Tracing


```
  Node {
    Id   String,
    Data Object,
    Child List <Node>
  }
```
  
